<?php
declare (strict_types = 1);

require_once __DIR__ . '/../NeuralNetwork.class.php';

use NeuralNetwork\Layer\Dense;
use NeuralNetwork\Layer\Dropout;

// Multivariate regression dataset (5 input features -> 1 output)
$samples = [
    [6.22, 68.67, 53.44, 582, 329.5], [6.22, 60.34, 60.38, 630, 325.75], [6.08, 50.29, 53.13, 767, 324],
    [6.74, 51.84, 54.18, 939, 373], [7.1, 53.54, 67.32, 808, 375.5], [7.11, 61.17, 83.03, 867, 384.5],
    [7.99, 53.02, 90.63, 885, 455.5], [8.54, 52.51, 84.45, 929.5, 501.25], [9.41, 61.15, 71.6, 1073, 546],
    [10.18, 77.39, 57.31, 929, 567.25], [11.27, 88.19, 49.61, 787.25, 600.25], [12.69, 86.32, 52.08, 761.5, 599.25],
    [11.09, 73.49, 54.36, 843.5, 724.75], [8.26, 60.8, 53.34, 783.75, 587.5], [7.67, 50.85, 48.16, 779.25, 568.25],
    [6.74, 53.47, 54.41, 680, 487.5], [6.68, 55.12, 65.83, 536.25, 401.5], [5.82, 54.29, 81.67, 542.5, 349.5],
    [5.24, 48.7, 88.73, 610.75, 407], [4.51, 52.77, 79.56, 568, 379], [3.96, 62.3, 68.11, 510.5, 350.75],
    [3.5, 77.41, 56.32, 532.75, 404.75], [3.83, 88.06, 47.58, 524.25, 396.25], [3.8, 83.3, 51.18, 637.25, 436.25],
    [3.38, 70.02, 52.98, 511.25, 347.75], [3.14, 58.04, 56.08, 528.25, 339.5], [2.99, 48.52, 52.65, 471, 326.25],
    [4.01, 50.93, 56.7, 457.5, 344], [3.66, 53.48, 61.38, 494.25, 366], [5.35, 56.01, 85.94, 586.5, 402.75],
    [5.83, 52.5, 92.13, 541.13, 414.5], [5.32, 53.76, 88.29, 473.13, 356.5], [4.29, 59.21, 65.62, 519.13, 378],
    [4.03, 80.38, 53.01, 450.38, 345], [4.14, 90.64, 51.56, 505.13, 366.25], [4.8, 88.61, 52.94, 458.38, 359],
    [4.63, 69.13, 58.82, 479.25, 354.25], [4.32, 56.39, 60.11, 661.38, 392.75], [3.89, 52.17, 53.88, 689.38, 424.5],
    [3.43, 54.98, 55.07, 676.13, 495.75], [3.71, 58.9, 67.83, 727.38, 582], [4.25, 60.61, 89.9, 689.63, 530],
    [4.49, 54.58, 93.97, 792.63, 629], [4.09, 53.71, 86.85, 838.63, 659.5], [3.97, 65.78, 72.09, 816.38, 722.5],
    [4.24, 87.55, 60.28, 759.13, 693.25], [4.31, 93.18, 54, 804.13, 754], [4.54, 87.59, 55.62, 787.13, 747.5],
    [4.42, 71.95, 60.44, 600.38, 629], [4.05, 60.83, 60.79, 674.88, 665.5], [3.9, 53.79, 53.98, 788.13, 757.5],
    [3.57, 55.24, 58.25, 606, 592.5], [3.24, 60.98, 68.81, 629.25, 647], [3.17, 61.03, 83.64, 614.88, 601.25],
    [2.67, 55.19, 88.88, 653.13, 646.5], [2.5, 56.27, 85.8, 666.63, 639], [2.17, 67.73, 67.91, 667.88, 656.5],
    [1.95, 82, 64.26, 658.88, 644], [2.43, 88.91, 59.98, 652.63, 660.25], [2.46, 86.23, 61.42, 645.63, 555.25],
    [2.95, 68.64, 67.29, 758.88, 672.5], [2.84, 65.1, 65.27, 892.63, 806.5], [2.85, 60.45, 60.73, 888.63, 802.75],
    [3.32, 62.28, 62.41, 895.63, 756.25], [3.54, 66.77, 74.13, 866.88, 755.75], [3.34, 64.8, 81.83, 863.5, 748],
    [3.33, 60.24, 93.01, 778.5, 698.25], [3.33, 61.33, 91.19, 781.63, 740.5], [3.81, 72.26, 81.11, 716.38, 719.5],
    [4.17, 80.77, 64.72, 684.5, 695.25], [4.04, 92.86, 55.26, 730.25, 683.25], [3.83, 91.68, 56.75, 706.63, 662],
    [3.62, 81.33, 61.66, 656.88, 679.25], [3.42, 65.58, 61.55, 663.63, 499], [3.62, 56.53, 58.94, 654.88, 495],
    [3.68, 58.1, 61.87, 679.13, 441.5], [3.64, 62.14, 78.51, 667.38, 428.25], [4.24, 62.17, 95.1, 668.25, 415.25],
    [4.71, 58.9, 104.1, 605.13, 422], [6, 60.22, 98.95, 555, 434], [4.9, 77.23, 83.47, 600.38, 457.5],
    [4.66, 94.22, 65.86, 697.13, 502], [4.58, 103.36, 57.55, 721.5, 514], [4.59, 97.9, 57.65, 628.13, 465.75],
    [4.05, 82.51, 61.38, 576.75, 424.25], [3.91, 65.39, 63.18, 530.38, 357], [3.92, 58.39, 60.91, 563.38, 359],
    [3.78, 58.18, 63.48, 478.63, 320.75], [4.12, 60.68, 81.97, 531.25, 376.75], [3.48, 62.36, 86.66, 578.38, 375.75],
    [2.99, 60.31, 101.85, 589.88, 397], [2.87, 61.7, 104.92, 503.25, 370], [2.83, 78.58, 83.78, 512, 384.5],
    [2.61, 86.42, 66.89, 512.88, 376.25], [2.85, 100.48, 60.19, 475.38, 362.5], [2.78, 104.47, 64.05, 477.88, 351.5],
    [2.84, 83.59, 67.3, 616.63, 414], [2.77, 66.93, 66.43, 498.13, 371], [2.66, 59.94, 63.76, 485.38, 363.75],
    [2.34, 63.33, 65.61, 512.25, 387.75], [2.09, 66.7, 76.68, 522.13, 382.25], [1.93, 66.22, 84.94, 475.63, 365],
    [2.28, 63.38, 101.02, 469.38, 358.75], [1.99, 64.11, 92.01, 479.38, 372], [1.73, 74.97, 77.1, 452.88, 353.5],
    [1.92, 83.49, 70.3, 474.5, 351.5], [1.92, 99.73, 64.1, 489.25, 390.25], [2.59, 91.46, 66.66, 463.75, 404.75],
    [2.82, 76.01, 70.9, 448, 358.75], [2.82, 69.46, 69.7, 407.25, 334.5], [2.99, 63.41, 64.09, 387.5, 301.5],
    [2.98, 66.69, 63.15, 401.75, 336.75], [2.55, 70.54, 73.57, 415.25, 354.75], [3.59, 71.24, 94.51, 403, 336.75],
    [3.3, 64.93, 93.6, 407.75, 352], [2.85, 62.1, 82.18, 421, 359.75], [2.88, 71.98, 82.66, 443.75, 366.75],
    [3.1, 92.46, 65.43, 425.75, 364.25], [3.15, 93.99, 62.07, 432.62, 358], [2.98, 83.58, 64.13, 429.5, 372],
    [2.98, 81.4, 69.97, 525.75, 370.5], [2.9, 64.4, 68.39, 474.25, 370.75], [2.98, 61.03, 64.75, 435.5, 342.25],
    [2.88, 63.68, 68.11, 448.25, 355.25], [3.01, 69.08, 81.38, 418.5, 345.75], [2.82, 67.54, 102.56, 434.38, 341.75],
    [3.69, 64.02, 108.38, 427.5, 350.75], [2.67, 65.53, 96.24, 451.5, 361.5], [2.69, 78.58, 90.28, 492.5, 374.5],
    [2.8, 99.55, 78.91, 451.75, 387.75], [2.8, 107.77, 66.88, 511.25, 392.5], [2.97, 96.81, 69.68, 524.75, 394],
    [2.83, 90.22, 76.21, 502, 350.25], [2.96, 78.35, 75.8, 554.5, 372.25], [3, 66.29, 73.1, 546.5, 351],
    [3.28, 68.77, 75.98, 510.5, 356.25], [4.09, 75.83, 93.03, 501.25, 363.25], [4.04, 74.64, 96.87, 515.5, 366.5],
    [3.11, 71.87, 110.08, 503, 375], [2.69, 73.74, 106.99, 516.5, 376.5], [2.95, 90.53, 94.84, 458.75, 362],
    [2.65, 96.76, 74.03, 458.5, 356.5], [2.64, 110.23, 71.3, 429, 353.25], [2.4, 107.62, 72.5, 504.88, 427],
    [2.37, 94.27, 79.28, 526, 420.25], [2.22, 73.63, 80.44, 486.5, 400.25], [2.56, 68.74, 74.7, 461.38, 358],
    [2.33, 70.56, 78.04, 495.5, 388], [2.65, 77.13, 94.68, 508.75, 390], [2.22, 78.4, 103.53, 542.12, 371.25],
    [2.02, 73.44, 105.69, 559.38, 387.75], [1.91, 74.35, 105.98, 553.38, 381.25], [1.79, 92.6, 87.23, 525.25, 366.5],
    [1.74, 102.03, 75.18, 567.75, 340.75], [1.75, 106.32, 66.77, 523.5, 311.5], [1.63, 104.58, 71.56, 521.62, 325.75],
    [1.77, 87.37, 80.27, 490.75, 338.5], [2.3, 74.77, 78.23, 531, 316], [1.92, 66.75, 71.68, 546.5, 348.5],
    [2.39, 71.13, 77.01, 578.12, 379], [2.61, 80.37, 81.52, 598.5, 398.5], [2.59, 77.53, 102.56, 581, 419.75],
    [2.71, 72.46, 106.46, 641.75, 484], [5.35, 74.91, 108.9, 662.62, 547], [2.62, 81.32, 82.93, 660.12, 555.5],
    [2.66, 101.86, 75.25, 618.75, 564.25], [2.91, 106, 67.89, 735.3, 740], [3, 108.44, 70.68, 664.12, 656.75],
];

$targets = [348.44, 343.06, 352.25, 410.32, 454.75, 494.23, 506.37, 450.97, 409.78, 466.66, 538.95, 739.85, 742.03, 849.61, 841.53, 745.23, 406.64, 244.89, 225.11, 258.63, 295.20, 287.47, 265.23, 266.63, 262.88, 275.10, 283.75, 274.38, 271.60, 270.88, 290.75, 267.13, 295.38, 314.75, 321.95, 312.50, 281.20, 275.00, 302.88, 347.20, 365.50, 392.25, 394.17, 399.75, 390.13, 360.80, 370.00, 416.63, 499.50, 495.63, 504.88, 531.00, 516.88, 503.63, 403.50, 392.00, 394.50, 438.50, 519.67, 534.38, 435.00, 409.00, 406.20, 406.50, 428.38, 392.90, 396.33, 411.20, 420.00, 400.75, 381.75, 369.50, 342.50, 340.38, 329.80, 301.00, 315.25, 340.88, 359.67, 374.90, 362.88, 344.00, 319.00, 325.50, 295.00, 293.00, 319.75, 333.25, 315.00, 306.25, 303.25, 308.72, 290.00, 260.00, 250.00, 278.75, 286.00, 269.00, 265.50, 253.75, 247.00, 251.50, 260.63, 238.63, 236.13, 234.50, 222.50, 204.50, 192.00, 189.63, 194.25, 195.00, 209.00, 242.75, 244.88, 279.25, 271.75, 240.93, 206.86, 188.54, 194.97, 194.71, 210.41, 263.82, 281.70, 264.16, 237.72, 252.57, 257.08, 253.24, 233.57, 229.46, 260.43, 277.17, 284.96, 303.56, 325.92, 312.72, 281.82, 276.46, 246.25, 233.16, 238.56, 256.97, 272.67, 271.24, 253.54, 252.57, 248.24, 230.67, 228.62, 231.67, 233.54, 250.10, 232.88, 209.73, 220.34, 232.80, 265.48, 262.54, 256.15, 256.72, 260.68, 308.82, 361.97, 363.95, 342.52, 357.12];

echo "Dataset: " . count($samples) . " samples with 5 features\n";
echo "Applying Min-Max normalization...\n";

// Calculate min/max for each feature (for normalization)
$featureMins = array_fill(0, 5, PHP_FLOAT_MAX);
$featureMaxs = array_fill(0, 5, PHP_FLOAT_MIN);
$targetMin = min($targets);
$targetMax = max($targets);

foreach ($samples as $sample) {
    for ($i = 0; $i < 5; $i++) {
        $featureMins[$i] = min($featureMins[$i], $sample[$i]);
        $featureMaxs[$i] = max($featureMaxs[$i], $sample[$i]);
    }
}

// Normalize samples to [0, 1]
$normalizedSamples = [];
foreach ($samples as $sample) {
    $normalized = [];
    for ($i = 0; $i < 5; $i++) {
        $range = $featureMaxs[$i] - $featureMins[$i];
        $normalized[$i] = $range > 0 ? ($sample[$i] - $featureMins[$i]) / $range : 0;
    }
    $normalizedSamples[] = $normalized;
}

// Normalize targets to [0, 1]
$targetRange = $targetMax - $targetMin;
$normalizedTargets = array_map(fn($t) => [($t - $targetMin) / $targetRange], $targets);

// echo "Feature ranges: \n";
// for ($i = 0; $i < 5; $i++) {
//     echo "  Feature $i: [" . number_format($featureMins[$i], 2) . ", " . number_format($featureMaxs[$i], 2) . "]\n";
// }
// echo "Target range: [" . number_format($targetMin, 2) . ", " . number_format($targetMax, 2) . "]\n\n";

echo "Training multivariate regression (with normalization)....\n";

// Simple network
$layers = [
    new Dense(5, 32, 'leaky-relu'),
    //new Dropout(0.2),
    new Dense(32, 16, 'leaky-relu'),
    new Dense(16, 1, 'linear'),
];

$nn = new \NeuralNetwork($layers);
$nn->configure([
    'learning_rate' => 0.001,
    'optimizer' => 'adam',
    'loss' => 'mse',
    'batch_size' => 16,
]);

$nn->train($normalizedSamples, $normalizedTargets, 5000, 100, false);

echo "\nTesting on first 5 samples:\n";
echo str_repeat("-", 80) . "\n";
printf("%-35s %-15s %-15s\n", "Input", "Predicted", "Actual");
echo str_repeat("-", 80) . "\n";

for ($i = 0; $i < 30; $i++) {
    // Predict with normalized input
    $predNormalized = $nn->predict($normalizedSamples[$i]);

    // Denormalize prediction back to original scale
    $pred = $predNormalized[0] * $targetRange + $targetMin;
    $actual = $targets[$i];
    $error = abs($pred - $actual);
    $errorPct = ($error / $actual) * 100;

    $inputStr = sprintf("[%.1f, %.1f, %.1f, %.0f, %.1f]",
        $samples[$i][0], $samples[$i][1], $samples[$i][2],
        $samples[$i][3], $samples[$i][4]);

    printf("%-35s %-15.2f %-15.2f (err: %.1f%%)\n",
        $inputStr, $pred, $actual, $errorPct);
}

// Calculate metrics
$totalError = 0;
$totalErrorPct = 0;
$maxError = 0;

for ($i = 0; $i < count($samples); $i++) {
    // Predict with normalized input
    $predNormalized = $nn->predict($normalizedSamples[$i]);

    // Denormalize prediction
    $pred = $predNormalized[0] * $targetRange + $targetMin;
    $actual = $targets[$i];
    $error = abs($pred - $actual);
    $errorPct = ($error / $actual) * 100;

    $totalError += $error;
    $totalErrorPct += $errorPct;
    $maxError = max($maxError, $error);
}

$avgError = $totalError / count($samples);
$avgErrorPct = $totalErrorPct / count($samples);

echo str_repeat("-", 70) . "\n";
echo "\nPerformance Summary:\n";
echo " - Average Absolute Error: " . number_format($avgError, 2) . "\n";
echo " - Average Error %: " . number_format($avgErrorPct, 2) . "%\n";
echo " - Maximum Error: " . number_format($maxError, 2) . "\n";
echo " - Total Samples: " . count($samples) . "\n";
?>
